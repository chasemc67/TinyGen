{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Awaitable\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from langchains.openai import run_llm_chain_for_input\n",
    "\n",
    "@dataclass\n",
    "class GithubFile:\n",
    "    filename: str\n",
    "    content: str\n",
    "\n",
    "@dataclass\n",
    "class ProcessedGithubFile:\n",
    "    originalFile: GithubFile\n",
    "    llmResponse: str\n",
    "\n",
    "mock_github_results: List[GithubFile] = [\n",
    "    GithubFile(\"test1.txt\", \"This is a test file\"),\n",
    "    GithubFile(\"test2.txt\", \"This is another test file\"),\n",
    "    GithubFile(\"test3.txt\", \"This file has a dog in it\"),\n",
    "    GithubFile(\"test4.txt\", \"This file has a cat in it\"),\n",
    "    GithubFile(\"test5.txt\", \"This file has a golden retriever in it\"),\n",
    "    GithubFile(\"test6.txt\", \"This is yet another test file\")\n",
    "]\n",
    "mock_user_prompt = \"find dogs within the files\"\n",
    "\n",
    "\n",
    "# Define the function you want to run on each object:\n",
    "async def process_item(item: GithubFile) -> ProcessedGithubFile:\n",
    "    # This is a placeholder function that doesn't do much.\n",
    "    # Replace it with whatever function you want to run.\n",
    "    # await asyncio.sleep(1)  # simulate IO delay\n",
    "    # return ProcessedGithubFile(item, f\"Processed {item.filename} with code {item.content}\")\n",
    "    #return f\"Processed {item.filename} with code {item.content}\"\n",
    "\n",
    "    result = run_llm_chain_for_input(mock_user_prompt, item.content)\n",
    "    return ProcessedGithubFile(item, result)\n",
    "\n",
    "\n",
    "\n",
    "# TODO since I think this syntax is dependent on the python version\n",
    "# We should find a way to define it such that heroku and local development will respect/enforce it\n",
    "async def process_all_items(items: List[GithubFile]) -> List[ProcessedGithubFile]:\n",
    "    # Create a list of tasks to run:\n",
    "    tasks = [process_item(item) for item in items]\n",
    "\n",
    "    # Run the tasks:\n",
    "    #loop = asyncio.get_event_loop()\n",
    "    # results = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Do something with the results:\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ProcessedGithubFile(originalFile=GithubFile(filename='test1.txt', content='This is a test file'), llmResponse='\\n\\n0'), ProcessedGithubFile(originalFile=GithubFile(filename='test2.txt', content='This is another test file'), llmResponse='\\n\\n50'), ProcessedGithubFile(originalFile=GithubFile(filename='test3.txt', content='This file has a dog in it'), llmResponse='\\n\\n100'), ProcessedGithubFile(originalFile=GithubFile(filename='test4.txt', content='This file has a cat in it'), llmResponse='\\n\\n0'), ProcessedGithubFile(originalFile=GithubFile(filename='test5.txt', content='This file has a golden retriever in it'), llmResponse='\\n\\n100'), ProcessedGithubFile(originalFile=GithubFile(filename='test6.txt', content='This is yet another test file'), llmResponse='\\n\\n50')]\n"
     ]
    }
   ],
   "source": [
    "results = await process_all_items(mock_github_results)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
